{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e1f68cf-3c7e-4137-ba56-c37a5ddae839",
   "metadata": {},
   "source": [
    "# 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fba7da3-6684-4092-8007-8164876c1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openvino-dev==2024.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af25dcd-3543-4fec-a5dd-7e66671c82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!omz_downloader -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd2c078-b01b-4f33-b0d4-629e2e96e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "!omz_downloader --name face-detection-adas-0001 --precision FP16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e908935c-60b6-4b4d-a8f7-c95f70681fc2",
   "metadata": {},
   "source": [
    "** intel 폴더가 생성되고 그 안에 face-detection 폴더 안에 모델이 다운로드된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f25a6-354d-4a79-bba3-0b463c4e1ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd38a7-2f9d-401e-a918-6aa29cc589c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "core=ov.Core()\n",
    "\n",
    "model=core.read_model(model=\"models/face-detection-adas-0001.xml\")\n",
    "face_model=core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "face_input_layer=face_model.input(0)\n",
    "face_output_layer=face_model.output(0)\n",
    "print(\"Input layer shape:\", face_input_layer.shape)\n",
    "print(\"Onput layer shape:\", face_output_layer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f11cd1-bfc4-448b-89a0-5b7df6529ee7",
   "metadata": {},
   "source": [
    "## Prepare Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb022e7e-ca41-4230-9860-be7c7e3b3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread(\"data/test.jpg\")  # 이미지를 불러온다.\n",
    "\n",
    "image.shape                        # 원래이미지의 정보를 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea393fc0-f680-4d19-b4d8-1855f04fb708",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image=cv2.resize(src=image, dsize=(672,384))  # input 사이즈로 조정->(3,672,384)\n",
    "transposed_image=resized_image.transpose(2,0,1)       #Transpose후 (3,384,672)로 조정\n",
    "input_image=np.expand_dims(transposed_image,0)        #차원확장 (1,3,384,672) 으로 조정\n",
    "\n",
    "input_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3e26d5-1335-4b00-b4ae-ee6b6da7dbdb",
   "metadata": {},
   "source": [
    "## Inference(추론)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46286b9e-2669-4f6d-9b9e-9dc26113ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_output=face_model([input_image])[face_output_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d397364a-7a7f-4854-a771-6242a1d39516",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5e2fd2-3109-49ff-9a73-3550a2628fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[참고]넘파이 배열을 이쁘게 보이게 한다.\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "print(face_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1752bcc2-3047-4dc8-9ccd-49d84fe039b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래 기본값으로 보이게 한다.\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=75, nanstr='nan', precision=8, suppress=False, threshold=1000, formatter=None)\n",
    "face_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223db44c-79eb-4d53-bd31-3183c2bebd28",
   "metadata": {},
   "source": [
    "## 후처리(이미지에 박스처리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022ae9e-421f-49d6-9ca8-d89403ce82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#추론한 값(output), 이미지(image), 임계값(conf)을 가져와 \n",
    "#이미지에 얼굴에 박스를 그리는 DrawBoundingBoxes함수\n",
    "def DrawBoundingBoxes(output, image, conf):\n",
    "\n",
    "    canvas = image.copy()\n",
    "    h,w,_ = canvas.shape \n",
    "\n",
    "    predictions = output[0][0]            # 하위 집합 데이터 프레임\n",
    "    confidence = predictions[:,2]         # conf 값 가져오기 [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "\n",
    "    top_predictions = predictions[(confidence>conf)]         # 임계값보다 큰 conf 값을 가진 예측만 선택\n",
    "\n",
    "    for detection in top_predictions:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # 상자 위치 결정\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")  # xmin, ymin, xmax, ymax에 상자 위치 값 지정\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)       # 사각형 만들기\n",
    "\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5c29d-4c57-44e7-9c4b-8e3a8c435715",
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = DrawBoundingBoxes(face_output, image, conf=0.5)\n",
    "\n",
    "cv2.imshow(\"Canvas\", canvas)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15082cf-18d5-40fc-a208-ff7fda5340f6",
   "metadata": {},
   "source": [
    "## 배포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e739c90-e979-48b4-80ac-b1b171f4c1ed",
   "metadata": {},
   "source": [
    "## Gradio 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55ca913-0a6e-45cc-9303-baffcf8d566f",
   "metadata": {},
   "source": [
    "### predict_image를 만들어야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d52ed-a5f2-4572-aa4d-b81daf20daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()\n",
    "options=core.available_devices\n",
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c8e66-6f42-45d5-a656-8084a5e9bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 1. AI 모델 불러오기 ,input_layer & output_layer 준비\n",
    "core = ov.Core()\n",
    "model = core.read_model(model=\"models/face-detection-adas-0001.xml\")\n",
    "face_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "face_input_layer = face_model.input(0)\n",
    "face_output_layer = face_model.output(0)\n",
    "\n",
    "# 2. 새로 입력된 이미지 데이터 전처리\n",
    "def preprocess(new_image):\n",
    "    # Convert the PIL image to a NumPy array and resize to 224x224\n",
    "    #image = np.array(new_image)  # Convert PIL image to numpy array\n",
    "    resized_image = cv2.resize(src=new_image, dsize=(672, 384)) \n",
    "    transposed_image = resized_image.transpose(2, 0, 1)\n",
    "    input_image = np.expand_dims(transposed_image, 0)\n",
    "    return input_image\n",
    "\n",
    "# 4. AI 추론 결과 후처리: 시각화(인식된 얼굴 주변에 박스 그리기)\n",
    "def DrawBoundingBoxes(new_image, face_output, conf):\n",
    "    canvas = new_image.copy()\n",
    "    h,w,_ = canvas.shape \n",
    "    predictions = face_output[0][0]            # 하위 집합 데이터 프레임\n",
    "    confidence = predictions[:,2]         # conf 값 가져오기 [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "    top_predictions = predictions[(confidence>conf)]         # 임계값보다 큰 conf 값을 가진 예측만 선택\n",
    "    for detection in top_predictions:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # 상자 위치 결정\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")  # xmin, ymin, xmax, ymax에 상자 위치 값 지정\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)       # 사각형 만들기\n",
    "    return canvas\n",
    "\n",
    "# 3. AI 추론\n",
    "def predict_image(new_image):\n",
    "    input_image = preprocess(new_image)  # Preprocess the image\n",
    "    face_output = face_model([input_image])[face_output_layer]  # Perform inference  \n",
    "    canvas = DrawBoundingBoxes(new_image, face_output, conf=0.5)\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac4fb5-8079-45eb-bc19-7a2de2b5a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Gradio 실행\n",
    "gr.Interface(fn=predict_image,\n",
    "             inputs=gr.Image(type=\"numpy\"),  # Use NumPy array\n",
    "             outputs=gr.Image(type=\"numpy\"),  # Output as NumPy array\n",
    "             examples=[\"./data/test.jpg\"]).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d29c0-242d-458f-b161-df2fad97279b",
   "metadata": {},
   "source": [
    "## 영상추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f39a2-8892-453d-8575-841a6cfd2056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# AI 모델 불러오기 ,input_layer & output_layer 준비\n",
    "core = ov.Core()\n",
    "model = core.read_model(model=\"models/face-detection-adas-0001.xml\")\n",
    "face_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "face_input_layer = face_model.input(0)\n",
    "face_output_layer = face_model.output(0)\n",
    "\n",
    "# 2. 새로 입력된 이미지 데이터 전처리\n",
    "def preprocess(new_image):\n",
    "    # Convert the PIL image to a NumPy array and resize to 224x224\n",
    "    #image = np.array(new_image)  # Convert PIL image to numpy array\n",
    "    resized_image = cv2.resize(src=new_image, dsize=(672, 384)) \n",
    "    transposed_image = resized_image.transpose(2, 0, 1)\n",
    "    input_image = np.expand_dims(transposed_image, 0)\n",
    "    return input_image\n",
    "\n",
    "# AI 추론 결과 후처리: 시각화(인식된 얼굴 주변에 박스 그리기)\n",
    "def DrawBoundingBoxes(new_image, face_output, conf):\n",
    "    canvas = new_image.copy()\n",
    "    h,w,_ = canvas.shape \n",
    "    predictions = face_output[0][0]            # 하위 집합 데이터 프레임\n",
    "    confidence = predictions[:,2]         # conf 값 가져오기 [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "    top_predictions = predictions[(confidence>conf)]         # 임계값보다 큰 conf 값을 가진 예측만 선택\n",
    "    for detection in top_predictions:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # 상자 위치 결정\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")  # xmin, ymin, xmax, ymax에 상자 위치 값 지정\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)       # 사각형 만들기\n",
    "    return canvas\n",
    "\n",
    "\n",
    "# 3. AI 추론\n",
    "def predict_image(new_image):\n",
    "    input_image = preprocess(new_image)  # Preprocess the image\n",
    "    face_output = face_model([input_image])[face_output_layer]  # Perform inference  \n",
    "    canvas = DrawBoundingBoxes(new_image, face_output, conf=0.5)\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b2550d-b871-4d35-8e6c-a311a44af3f3",
   "metadata": {},
   "source": [
    "### ->웹캠출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134f77fc-408c-4213-a2f9-4251a7cb9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera=cv2.VideoCapture(0)\n",
    "# bg=cv2.imread(\"data/background.jpg\")\n",
    "camera=cv2.VideoCapture(\"data/video.mp4\")\n",
    "#camera = cv2.VideoCapture(0) #create a VideoCapture object with the 'first' camera (your webcam)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()             # Capture frame by frame      \n",
    "    if ret == False:\n",
    "        break\n",
    "    # AI 추론을 위한 데이터 전처리\n",
    "    resized_frame = cv2.resize(src=frame, dsize=(672, 384)) \n",
    "    transposed_frame = resized_frame.transpose(2, 0, 1)\n",
    "    input_frame = np.expand_dims(transposed_frame, 0) \n",
    "    # AI 추론\n",
    "    face_output = face_model([input_frame])[face_output_layer]\n",
    "    # AI 추론 결과 시각화: 박스 그기기\n",
    "    canvas = DrawBoundingBoxes(frame, face_output, conf=0.5)\n",
    "    cv2.imshow('Press Spacebar to Exit', canvas)\n",
    "    # 영상 종료: 스페이스 바\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):  # Stop if spacebar is detected\n",
    "        break\n",
    "camera.release()                           # Cleanup after spacebar is detected.\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
